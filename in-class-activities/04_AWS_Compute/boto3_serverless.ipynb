{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f00d587",
   "metadata": {},
   "source": [
    "## Introduction to Boto3 and AWS Serverless Solutions\n",
    "\n",
    "Let's say that we wanted to detect objects in an image, extract text from images. We could write and train our own classifiers, run our classifier on a server (e.g. an EC2 instance) and use this to make predictions. This requires a lot of time and energy in selecting the appropriate hardware, software, techniques, etc. necessary to perform these operations.\n",
    "\n",
    "For this reason, all the major cloud providers offer serverless \"functions as a service\" which are pre-trained/coded models that you simply need to provide data to and you will receive a response. Your cloud provider (e.g. AWS) will spin up the compute instances necessary to actually run the code. \n",
    "\n",
    "You can access all of these through the AWS Console, but it is easier to integrate them into your existing code via the Boto3 SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba93331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168eac2",
   "metadata": {},
   "source": [
    "For instance, we can interact with AWS' image recognition functions like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekog = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7840ef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Architecture', 99.18966674804688),\n",
       " ('Building', 99.18966674804688),\n",
       " ('Campus', 99.18966674804688),\n",
       " ('Person', 97.88367462158203),\n",
       " ('City', 97.4571533203125)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the objects in the provided image\n",
    "with open('uchicago.jpg', 'rb') as image:\n",
    "    response = rekog.detect_labels(Image={'Bytes': image.read()})\n",
    "    \n",
    "[(label['Name'], label['Confidence']) for label in response['Labels']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c9abac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also count number of instances of each label: e.g. \"Person\" - label 3\n",
    "len(response['Labels'][3]['Instances']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae40030",
   "metadata": {},
   "source": [
    "We can use rekognition to detect text in images as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42b3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uchicago_sign.jpg', 'rb') as image:\n",
    "    response = rekog.detect_text(Image={'Bytes': image.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44468f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text:THE UNIVERSITY OF\n",
      "Confidence: 99.62%\n",
      "Detected text:CHICAGO\n",
      "Confidence: 99.58%\n"
     ]
    }
   ],
   "source": [
    "for text in response['TextDetections']:\n",
    "    if text['Type'] == 'LINE' and text['Confidence'] > 90:\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a060762",
   "metadata": {},
   "source": [
    "If you have custom workflows, Rekognition might not be the best option, but for many general applications, this will likely handle everything that you need to do and is really easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab878d",
   "metadata": {},
   "source": [
    "You will have a chance to practice using more of these serverless tools in the DataCamp course that we've assigned as one of the readings for Monday's class, but this should give you a taste of some of the functionality that is available to you right out of the box.\n",
    "\n",
    "----\n",
    "\n",
    "**AWS Lambda Functions**\n",
    "\n",
    "We can also create our own custom serverless functions as well, though, via AWS Lambda... \n",
    "\n",
    "*Go to AWS Console and create/deploy sample Lambda function (called `hello_world`):*\n",
    "\n",
    "```python\n",
    "def lambda_handler(event, context):\n",
    "    # test: {'key1': 1, 'key2': 2}\n",
    "    total = event['key1'] + event['key2']\n",
    "    return total\n",
    "```\n",
    "\n",
    "Can write code of arbitrary complexity in here, assuming it's going to be a relatively quick operation (e.g. less than 300s)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c906cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_lambda = boto3.client('lambda')\n",
    "\n",
    "test_data = {'key1': 1, 'key2': 2}\n",
    "\n",
    "# run synchronously:\n",
    "r = aws_lambda.invoke(FunctionName='hello_world',\n",
    "                      InvocationType='RequestResponse',\n",
    "                      Payload=json.dumps(test_data))\n",
    "json.loads(r['Payload'].read()) # print out response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "396c00ef",
   "metadata": {},
   "source": [
    "Can also upload Lambda functions programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbad35fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access our class IAM role, which allows Lambda\n",
    "# to interact with other AWS resources\n",
    "aws_lambda = boto3.client('lambda')\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')\n",
    "\n",
    "# Open zipped directory\n",
    "with open('hello_world.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='hello_world_programmatic',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda_function.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=300\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "        FunctionName='hello_world_programmatic',\n",
    "        ZipFile=lambda_zip\n",
    "        )\n",
    "\n",
    "lambda_arn = response['FunctionArn']\n",
    "\n",
    "# run synchronously:\n",
    "r = aws_lambda.invoke(FunctionName='hello_world_programmatic',\n",
    "                      InvocationType='RequestResponse',\n",
    "                      Payload=json.dumps(test_data))\n",
    "json.loads(r['Payload'].read()) # print out response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05afb8b",
   "metadata": {},
   "source": [
    "Currently still running all of this code serially, though. Real advantage of\n",
    "Lambda is that it scales automatically to meet concurrent demand, meaning\n",
    "that it will automatically parallelize based on how many concurrent invocations\n",
    "it receives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb04957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. write function to invoke our function for us and pass in data:\n",
    "def invoke_function(data):\n",
    "    r = aws_lambda.invoke(FunctionName='hello_world_programmatic',\n",
    "                          InvocationType='RequestResponse',\n",
    "                          Payload=json.dumps(data))\n",
    "    return json.loads(r['Payload'].read())\n",
    "\n",
    "# 2. Demo that lambda function will scale out if called concurrently on different threads locally\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = executor.map(invoke_function, [test_data for _ in range(10)])\n",
    "\n",
    "# 3. In AWS Console: confirm that we had >1 concurrent executions (takes a few seconds to update)\n",
    "# Same results too:\n",
    "[result for result in results]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52465c0",
   "metadata": {},
   "source": [
    "This capacity to scale based on concurrent demand makes Lambda functions great for event-driven workflows (which we'll talk in more detail about in a couple of weeks).\n",
    "\n",
    "For batch-job types of tasks, though, we should ideally be able to scale out to as many available Lambda workers as possible (i.e. thousands of concurrent function invocations on different segments of a dataset -- a serverless domain decomposition). In the above workflow, though, our local CPU is still a major bottleneck (we can only invoke as many concurrent Lambda workers as local multithreading allows). We'll revisit the question of how to scale out these batch workflows further when introduce AWS [Step Functions](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html), which can orchestrate large, embarrassingly parallel code execution across many Lambda workers entirely in cloud (i.e. no local bottleneck!)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
